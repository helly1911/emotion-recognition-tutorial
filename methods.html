<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>computer vision</title>
    <link rel="stylesheet" type="text/css" href="css.css">
</head>
<body>
    <div class="mainNav">
    <header><h2>Traditional Techniques For Emotion Recognition</h2></header>
    <nav id="nav">
        <ul class="style">
            <li><a href="index.html">Introduction</a></li>
            <li><a href="process.html">Process</a></li>
            <li class="active"><a href="methods.html">Methods</a></li>
            <li><a href="results.html">Results</a></li>
            <li><a href="references.html">References</a></li>
        </ul>
    </nav>
</div>
<div class="mainBody">
    <div class="mainDiv">
        <main>
            <h2>Methods</h2>
        </main>
    </div>
    <div class="subDiv">
        <div>
        <h3>Face Detection Algorithm</h3>
        <h3>Haar Cascading</h3>
        <p>Haar Cascading is the machine learning-based approach where lot of psitive and negative images are used to train the classifier.</p>
        <h4>Haar Cascading Algorithm has four stages.</h4>
        <ol>
            <li>Haar Feature Selection
                <ul>
                    <li>Haar features are used to find certain charecteristics which are shared by the human faces.</li>
                    <li>Mainly there are three types of Haar Features as shown in fig.
                        <ul>
                            <li>Two Rectangle feature: This will calculate the feature value by taking the difference between sum of pixles inside two rectangular regions</li>
                            <li>Three-rectangle feature: This will calculate the feature value by taking the sum of two outside rectangles pixel and subtract this with sum of pixel values of center rectangle.</li>
                            <li>Four-rectangle feature: This will calculate the feature value by taking the difference between diagonal pairs of rectangles.</li>
                        </ul>

                    </li>
                    <br>
                    <img src="haar_cascading1.png" alt="types of Haar Features" />
                    <figcaption>Fig. 2.1.1 Haar Features <b>[1]</b></figcaption>
                </ul>
            </li>
            <li>Creating Integral Images</li>
                <ul>
                    <li>Now, the next step is to calculate the sum of every pixels above and left of the corresponding pixels. After doing this process the input image is converted to integral image
                        </li>
                
                </ul>
            <li>Adaboost Training</li>
            <ul>
                <li>AdaBoost training algorithm is a ensembler classifier. Since this is a weak classifier it is made as a strong classifier by learning multiple times. </li>
                <li>The first two features selected by AdaBoost for the task of face detection are easily interpreted. First feature: the region of the eyes is often darker than the region of the nose and cheeks. Second feature: the eyes are darker than the bridge of the nose.</li>
            </ul>
            <li>Cascading Classifier</li>
            <ul>
                <li>Now the final step is to identify the portion of the image selected that contains the face or non face. To identify this we use a cascade classifier which consists of a number of stages with strong classifiers in each stage.Moreover, if the selected part of the input image is non face then it would be discard immediately and if the selected part is a face then it is passed to the next stage.</li>
                <li>The main idea is that if the portion of the input image passses through the more cascade stages then the probability that the selected part is a face will be higher.
                </li>
                <br>
                <img src="haar_cascading2.png" alt="Cascading Classifier">
                <figcaption>Fig. 2.1.2 Haar Classification <b>[1]</b> </figcaption>
            </ul>
        </ol>
    </div>

    <div>
        <h3>Feature Extraction different techniques</h3>
        <h3>Local Binary Pattern</h3> 
        <p>Local Binary Pattern is a simple yet effective texture operator that labels the pixel of an image by thresholding the neighborhood of each pixel and considers the image as a binary number.</p>  
        <p>Steps for finding Features using LBP:</p>
        <ol>
            <li>Convert the whole image as a window of 3*3 pixel</li>
            <li>Now we set the threshold as central value of the matrix</li>
            <li>Then check for each neighbor value if it is equal or greater than the threshold value then set 1 else 0.</li>
            <li>Now we perform histogram calculation in which we multiply each cell binary value to 2n where n=0 to 7.</li>
            <li>Then sum of all histogram values which give feature vector of the entire image.</li>
        </ol>
        <img src="LBP.png" alt="LBP Process">
        <figcaption>Fig. 2.2 Local Binary Pattern Algorithm Example <b>[3]</b></figcaption>
        <h3>Gabor Filter</h3>
        <p>GF can effectively express the texture features. It captures the salient visual properties and has greatly successful results in face recognition. </p>
        <p>Gabor filters with different frequencies and with orientations in different directions (similar to those of the human visual system) have been used to localize and extract edges from images.since edges are rich in high frequency components, whereas other regions of an image are relatively smooth in nature.</p>
        <h3>Histogram of Oriented Gradients</h3>
        <p>The histogram of oriented gradients (HOG) is a feature descriptor used in computer vision and image processing for the purpose of object detection. The technique counts occurrences of gradient orientation in localized portions of an image. This method is similar to that of edge orientation histograms, scale-invariant feature transform descriptors, and shape contexts, but differs in that it is computed on a dense grid of uniformly spaced cells and uses overlapping local contrast normalization for improved accuracy.</p>
        <p>Steps for finding featuresusing HOG</p>
        <ol>
            <li>Gradients are computed in the ROI(region of interest) regions</li>
            <li>Binning done according to orientation</li>
            <li>Grouping of cells into large blocks and Normalization of each block</li>
            <li>Extraction of HOG features are stored in a feature vector</li>
            <li>Repeated for all frames in a given video and the final concatenated feature vector is obtained which will be given as input to the classifier</li>
        </ol>
        <h3>Discrete Cosine Transform</h3>
        <p>Discrete Cosine Transform (DCT) is a technique to convert data of the image into its elementary frequency components. DCT of an image consist of three frequency components low, medium and high frequency. DCTs usually works on fixed discrete sequences.</p>
        <p> The two main issues that occurs on continuous cosine transform are we have to specify whether the function is even or odd and also we have to specify at what instant the function is even or odd. </p>
    </div>
    <div>
        <h3>Feature Classification Algorithm</h3>
        <h3>Support Vector machine</h3>
        <p>The objective of the support vector machine algorithm is to find a hyperplane in N-dimensional space(N â€” the number of features) that distinctly classifies the data points. There are some extensions such as Soft Margin, Non-linear, and Multiclass SVM Classification that make SVM more robust and adaptable to a real-world problem.</p>
        <img src="svm.png" alt="svm Process">
        <figcaption>Fig. 2.3 Support Vector Machine classification example <b>[3]</b></figcaption>
       
        <p>Advantages:</p>
        <ul>
            <li>On experimental results, shows high performance..</li>
            <li>Data set dimensionality has a low dependency.</li>
        </ul>
        <p>Disadvantages:</p>
        <ul>
            <li>In the case of categorical or missing value SVM needs preprocessing.</li>
            <li>Difficult interpretation of the resulting model.</li>
            
        </ul>
        <h3>k Nearest Neighbor</h3>
        <p>K-Nearest Neighbour (KNN) is an instance based learning in which the training data set is stored, so that a classification for a new unclassified record may be found simply by comparing it to the most similar records in the training set. The training examples are vectors in a multidimensional feature space, each with a class label. The training phase of the algorithm consists only of storing the feature vectors and class labels of the training samples. In the classification phase, k is a user-defined constant, and an unlabeled vector (a query or test point) is classified by assigning the label which is most frequent among the k training samples nearest to that query point.</p>
        <p>Advantages:</p>
        <ul>
            <li>The cost of the learning process is zero</li>
            <li>No assumptions about the characteristics of the concepts to learn have to be done</li>
            <li>Complex concepts can be learned by local approximation using simple procedures</li>
        </ul>
        <p>Disadvantages:</p>
        <ul>
            <li>The model cannot be interpreted.</li>
            <li>It is computationally expensive to find the k nearest neighbors when the dataset is very large.</li>
            <li>Performance depends on the number of dimensions that we have.</li>
        </ul>
        <h3>Random Forest</h3>
        <p>Random Forest Classifiers are entity-based training classifiers for classification by constructing a multi-attitude of decision trees at learning and output the label. At the inputting phase, it produces multi-altitude decision trees and multiple decision trees are produced at the outputting phase. By randomly selecting trees the correlation can be reduced thereby prediction power and accuracy increase.[3]</p>
        <p>Advantages:</p>
        <ul>
            <li>It is simple to explain and grasp and it does not need any parameters.</li>
            <li>It eliminates the need for pruning the trees by entering it easily if any parameter exists.</li>
            <li>They are very fast and scalable. </li>
            <li>It automatically generates symbols in a class.</li>
            
        </ul>
        <p>Disadvantages:</p>
        <ul>
            <li>They simply overfit its class.</li>
            <!-- <li>It takes lot of memory space which is required to store 100s of decision trees.</li>
            <li>intrpretebility of random forest is less as compared to decision tree.</li> -->
            
        </ul>
    </div>


    </div>
    
    
</div>

    
</body>
</html>